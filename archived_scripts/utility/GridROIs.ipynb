{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352bb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from lib.file.TIF import *\n",
    "from lib.analysis.ROI_identification import *\n",
    "from lib.file.ROI_writer import ROIFileWriter\n",
    "from lib.file.ROI_reader import ROIFileReader\n",
    "from lib.file.TSV import RegionExporter\n",
    "from lib.analysis.align import ImageAlign\n",
    "from lib.file.DAT import TracesDAT\n",
    "from lib.trace import Tracer\n",
    "from lib.utilities import *\n",
    "from lib.analysis.laminar_dist import *\n",
    "from lib.analysis.grid_latency import *\n",
    "\n",
    "####### GRID ROIS #######\n",
    "# for each recording:\n",
    "## 1) divide the entire frame of recording into grid of square n_sq x n_sq ROIs\n",
    "## 2) write these grid square ROIs to file\n",
    "## 3) take SNRs and latencies to .dat file of each ROI from PhotoZ\n",
    "## filter out no-response grid squares by SNR cutoff (or manual inspection?)\n",
    "## write out output file of (ROI center x, ROI center y, SNR, latency)\n",
    "## analysis: directed graph analysis of latency, 3-D plot of latency, 3-D plot of SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88e7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/jjudge3/Desktop/Data/mm_full_pipeline_targets/mm_hidden/\"\n",
    "\n",
    "n_sq = 20  # number of pixels of each square edge in the grid.\n",
    "max_num_rois = 100  # SNR cutoff \n",
    "latency_tolerance = 0.35  # ms tolerance to be counted simultaneous\n",
    "\n",
    "# sets of files in each slice directory -- naming convention\n",
    "# input\n",
    "corners_file_prefix_layer = 'corners_layer'  # defines axes of L4 boundaries\n",
    "electrode_file_prefix = 'electrode'\n",
    "# also needed: 01_01_01_snr.dat\n",
    "\n",
    "# output files\n",
    "rois_file_prefix = 'sq_rois_' + str(n_sq) + \"x\" + str(n_sq) \n",
    "rois_centers_filenames = \"roi_centers.txt\"\n",
    "\n",
    "image_data = {}\n",
    "n_plots = 5000  # show up to how many plots\n",
    "\n",
    "disable_photoZ_interact = True\n",
    "initialize_photoZ = False\n",
    "rewrite_data_files = True\n",
    "skip_grid_drawing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65dd777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up PhotoZ (open it manually)\n",
    "aPhz = AutoPhotoZ(data_dir=data_dir)\n",
    "if initialize_photoZ and not disable_photoZ_interact:\n",
    "    aPhz.prepare_photoZ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70587cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tslice directory count: 0\n",
      "\tmissing_la_file_count: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "slice_count = 0\n",
    "missing_la_file_count = 0\n",
    "for subdir, dirs, files in os.walk(data_dir):\n",
    "    if 'notUsable' in subdir:\n",
    "        continue\n",
    "    if 'selected_zda' not in subdir:\n",
    "        continue\n",
    "    print(subdir)\n",
    "    subdir += '/'\n",
    "    for filename in files:\n",
    "        fn = filename.split(\".\")[0]\n",
    "        if (fn.endswith(\"_snr\") or fn.startswith(\"SNR\")) and \"roi\" not in fn:\n",
    "            name_parse = filename[:8]  # of the format 07-01-01\n",
    "            if fn.startswith(\"SNR\"):\n",
    "                name_parse = filename[4:11]\n",
    "            try:\n",
    "                sep = \"_\"\n",
    "                if \"-\" in name_parse:\n",
    "                    sep = \"-\"\n",
    "                slic, loc, rec = [int(x) for x in name_parse.split(sep)]\n",
    "            except ValueError:\n",
    "                print(\"Could not parse:\", name_parse)\n",
    "                continue\n",
    "            if slic not in image_data:\n",
    "                image_data[slic] = {}\n",
    "            if loc not in image_data[slic]:\n",
    "                image_data[slic][loc] = {}\n",
    "            if rec not in image_data[slic][loc]:\n",
    "                image_data[slic][loc][rec] = {}\n",
    "            if subdir not in image_data[slic][loc][rec]:\n",
    "                image_data[slic][loc][rec][subdir] = {}\n",
    "\n",
    "            snr = np.loadtxt(subdir + filename,\n",
    "                             delimiter='\\t',\n",
    "                             usecols=(1,))\n",
    "            width = int(np.sqrt(snr.shape[0]))\n",
    "            snr = snr.reshape((width, width))\n",
    "            n_grid_size = int(width / n_sq)  # how many squares will fit along frame edge\n",
    "            image_data[slic][loc][rec][subdir]['snr_map'] = snr\n",
    "            print(\"slice\", slic, \", rec\", rec)\n",
    "            \n",
    "            if skip_grid_drawing:\n",
    "                continue\n",
    "            # corners file: 2 points p1, p2 to define the edge along which to measure\n",
    "            la_file = subdir + corners_file_prefix_layer + '.dat'\n",
    "            lines = None\n",
    "            if not os.path.exists(la_file):\n",
    "                missing_la_file_count += 1\n",
    "            else:\n",
    "                print(\"Processing\", la_file)\n",
    "                slice_count += 1\n",
    "                with open(la_file, 'r') as f:\n",
    "                    lines = f.readlines() \n",
    "                corners = [int(x) for x in lines[4:]] # the last 4 lines are diode numbers of corners\n",
    "                layer_axes = LayerAxes(corners)\n",
    "                laminar_axis, laminar_axis_2 = layer_axes.get_layer_axes()\n",
    "                print(\"laminar axis unit vectors:\", laminar_axis.get_unit_vector(), \n",
    "                      laminar_axis_2.get_unit_vector())\n",
    "\n",
    "                # make our own square ROIs aligned to the list of edges and write them to a .dat file\n",
    "                ################################\n",
    "                # Limit # of ROIs by SNR to n highest SNR ROIs so that we can do\n",
    "                #        smaller ROIs without exceeding 100-ROI-per-file cap\n",
    "                ################################\n",
    "                roi_cr = SquareROICreator(layer_axes, roi_width=n_sq, max_num_rois=max_num_rois, snr=snr)\n",
    "                rois = roi_cr.get_rois()  # list of LaminarROI objects\n",
    "                roi_centers = roi_cr.get_roi_centers(rounded=True) \n",
    "                # print(\"ROI centers:\", roi_centers)\n",
    "                roi_cr.write_roi_centers_to_file(subdir + \"/\" + rois_centers_filenames)\n",
    "\n",
    "                # write these ROIs to file\n",
    "                roi_fn = roi_cr.write_roi_file(subdir, rois_file_prefix)\n",
    "                print(\"Created file:\", roi_fn)\n",
    "\n",
    "                # open stim point roi as a single integer (its diode number) in variable stim_pt\n",
    "                sp_file = subdir + electrode_file_prefix + '.dat'\n",
    "                with open(sp_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                stim_pt = int(lines[-1]) # last line is always electrode location\n",
    "                aux_obj = LaminarROI([stim_pt]).get_points()\n",
    "                stim_pt = aux_obj[0]  # should be a list of len 2, representing px location [x, y]\n",
    "                #print(\"Stim point:\", stim_pt)\n",
    "\n",
    "                # run laminar dist computation\n",
    "                laminar_distances_obj = LaminarDistance(laminar_axis, rois, stim_pt)\n",
    "                laminar_distances = laminar_distances_obj.compute_laminar_distances()\n",
    "                laminar_distances = [round(ld, 2) for ld in laminar_distances]\n",
    "                #print('laminar_distances:', laminar_distances)  # a list of integers with same indexing as rois\n",
    "\n",
    "                # run laminar dist again with the other axis\n",
    "                laminar_distances_2 = LaminarDistance(laminar_axis_2, rois, stim_pt).compute_laminar_distances()\n",
    "                laminar_distances_2 = [round(ld, 2) for ld in laminar_distances_2]\n",
    "                #print('laminar_distances 2:', laminar_distances_2)  # a list of integers with same indexing as rois\n",
    "\n",
    "                # write averaged laminar distances to file\n",
    "                avg_laminar_distances = [round(\n",
    "                    (laminar_distances[i] + laminar_distances_2[i]) / 2,\n",
    "                    2)\n",
    "                                        for i in range(len(laminar_distances))]\n",
    "                #print('laminar_distances averaged :', avg_laminar_distances) \n",
    "                ld_filename_base = la_file[:-4] + \"_\"\n",
    "                laminar_distances_obj.write_laminar_distance_file(ld_filename_base, avg_laminar_distances)\n",
    "\n",
    "                #image_data[slic][loc][rec][subdir] = {\n",
    "                #    'snr': snr,\n",
    "                #    'filename': filename}\n",
    "\n",
    "                # Now that the data is stored, show intermediate computations in plot\n",
    "                if n_plots > 0:\n",
    "                    lines = [laminar_axis.get_line_repr(),\n",
    "                             laminar_axis_2.get_line_repr()]\n",
    "                    line_colors = ['red', 'yellow']\n",
    "                    linewidths = [4,4]\n",
    "                    other_colors = ['red', 'green', 'blue', 'white', 'purple']\n",
    "                    roi_colors = []\n",
    "\n",
    "                    # laminar aux lines\n",
    "                    uv = laminar_axis.get_unit_vector()\n",
    "                    for i in range(len(laminar_distances)):\n",
    "                        ld = laminar_distances[i]\n",
    "                        jiggle = i - int(len(laminar_distances) / 2)\n",
    "                        uv_perp = Line(laminar_axis.get_start_point(), \n",
    "                                       laminar_axis_2.get_start_point()).get_unit_vector()\n",
    "                        stim_proxy_pt = [stim_pt[0] - jiggle * uv_perp[0], \n",
    "                                         stim_pt[1] - jiggle * uv_perp[1]]\n",
    "                        measure_vector = [uv[0] * ld + stim_proxy_pt[0], uv[1] * ld + stim_proxy_pt[1]]\n",
    "                        lines.append([measure_vector, stim_proxy_pt])\n",
    "                        this_color = other_colors[i % len(other_colors)]\n",
    "                        line_colors.append(this_color)\n",
    "                        roi_colors.append(this_color)\n",
    "                        linewidths.append(1)\n",
    "\n",
    "                    GridVisualization(snr, stim_pt, roi_centers, layer_axes.get_corners(),\n",
    "                                      lines, line_colors, linewidths,\n",
    "                                      rois, roi_colors,\n",
    "                                      save_dir=subdir+\"GridVisual1\"+name_parse+'.png')\n",
    "                    n_plots -= 1\n",
    "\n",
    "print(\"\\tslice directory count:\", slice_count)\n",
    "print(\"\\tmissing_la_file_count:\", missing_la_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19191fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tslice directory count: 0\n",
      "\tmissing_roi_file_count: 0\n"
     ]
    }
   ],
   "source": [
    "## 3) take SNRs and latencies to .dat file of each ROI from PhotoZ\n",
    "slice_count = 0\n",
    "missing_roi_file_count = 0\n",
    "if not disable_photoZ_interact:\n",
    "    for subdir, dirs, files in os.walk(data_dir):\n",
    "        if 'notUsable' in subdir:\n",
    "            continue\n",
    "        if 'selected_zda' not in subdir:\n",
    "            continue\n",
    "\n",
    "        for zda_file in files:\n",
    "            if zda_file.endswith('.zda'):\n",
    "                rec_id = zda_file.split('.')[0]\n",
    "                slic_id, loc_id, _ = [int(x) for x in rec_id.split(\"_\")]\n",
    "                print(rec_id)\n",
    "                \n",
    "                # check for existing files\n",
    "                filename_end = \"_rois_\" + rec_id + \".dat\"\n",
    "                snr_filename = subdir + \"/\" + \"snr_\" + filename_end\n",
    "                latency_filename = subdir + \"/\" + \"latency_\" + filename_end                \n",
    "                need_to_open_zda = rewrite_data_files or ((not os.path.isfile(snr_filename)) \n",
    "                                        or (not os.path.isfile(latency_filename)))\n",
    "                slice_count += 1\n",
    "                \n",
    "                if need_to_open_zda:\n",
    "                    \n",
    "                    roi_fn = rois_file_prefix + \".dat\"\n",
    "                    if roi_fn not in files:\n",
    "                        print(\"\\t\", subdir, \"has no file named\", rois_file_prefix + \".dat\") \n",
    "                        missing_roi_file_count += 1\n",
    "                        continue\n",
    "                    roi_fn = subdir + \"/\" + roi_fn\n",
    "                    \n",
    "                    # open this zda file in photoZ\n",
    "                    aPhz = AutoPhotoZ(data_dir=subdir)\n",
    "                    aPhz.select_PhotoZ()\n",
    "\n",
    "                    print(\"\\n\\nOpening\", zda_file)\n",
    "                    aPhz.open_zda_file(subdir + \"/\" + zda_file)\n",
    "\n",
    "                    # open ROI file\n",
    "                    aPhz.select_roi_tab()\n",
    "                    aPhz.open_roi_file(roi_fn)\n",
    "\n",
    "                    # save SNR values\n",
    "                    aPhz.select_SNR_trace_value()\n",
    "                    aPhz.save_trace_values(snr_filename)\n",
    "\n",
    "                    # save latency values\n",
    "                    aPhz.select_latency_trace_value()\n",
    "                    aPhz.save_trace_values(latency_filename)\n",
    "\n",
    "                else:\n",
    "                    print(\"snr_\" + filename_end, \"and\", \"latency_\" + filename_end, \"already exist in\", subdir)\n",
    "\n",
    "print(\"\\tslice directory count:\", slice_count)\n",
    "print(\"\\tmissing_roi_file_count:\", missing_roi_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f3be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## filter out no-response grid squares by SNR cutoff (or manual inspection?)\\n###   Read in the SNR/latency files/roi center files\\nslice_count = 0\\nfor slic in image_data:\\n    for loc in image_data[slic]:\\n        for rec in image_data[slic][loc]:\\n            for subdir in image_data[slic][loc][rec]:\\n                slice_count += 1\\n                def pad_z2(x):\\n                    x = str(x)\\n                    while len(x) < 2:\\n                        x = \\'0\\' + x\\n                    return x\\n                \\n                rec_id = pad_z2(slic) + \"_\" + pad_z2(loc) + \"_\" + pad_z2(rec)\\n                \\n                filename_end = \"_rois_\" + rec_id + \".dat\"\\n                snr_filename = subdir + \"/\" + \"SNR_\" + filename_end\\n                latency_filename = subdir + \"/\" + \"latency_\" + filename_end \\n                roi_center_filename = subdir + \"/\" + rois_centers_filenames\\n\\n\\n                snr_df = pd.read_csv(snr_filename, sep=\\'\\t\\', header=None,\\n                                     names=[\\'Index\\',  \\'SNR\\'])\\n                latency_df = pd.read_csv(latency_filename, sep=\\'\\t\\', header=None,\\n                                     names=[\\'ROI Index\\',  \\'Latency\\'])\\n                roi_center_df = pd.read_csv(roi_center_filename, sep=\\'\\t\\', header=None,\\n                                     names=[\\'Center x\\',  \\'Center y\\'])\\n                \\n                combined_df = roi_center_df.join(latency_df)\\n                combined_df = combined_df.join(snr_df[[\\'SNR\\']])\\n                print(subdir, rec_id)\\n                \\n                ############## Analysis: ############################\\n                ##### 1) directed graph analysis of latency #########\\n                ##### 2) 3-D plot of latency ########################\\n                ##### 3) 3-D plot of SNR ############################\\n                #####################################################\\n                \\n                # 1) directed graph analysis of latency\\n                nd_list = [Node([row[[\\'Center x\\']][0], row[[\\'Center y\\']][0]],\\n                                 row[[\\'Latency\\']][0],\\n                                 row[[\\'SNR\\']][0]) for _, row in combined_df.iterrows()]\\n                grid = Grid(nd_list, n_sq, latency_tolerance=latency_tolerance)\\n                \\n                ## a) determine latency ordering on directed graph\\n                grid.populate_latency_matrix()\\n                grid.calculate_current_field()  # current flow vectors of all nodes\\n                \\n                ## b) visualize\\n                snr_map = None\\n                try:\\n                    snr_map = image_data[slic][loc][rec][subdir][\\'snr_map\\']\\n                except Exception as e:\\n                    snr_map = np.zeros((80, 80))  # default\\n                grid.visualize_spatial_flow(snr_map=snr_map,\\n                                            save_dir=subdir+\"GridVisual1\"+name_parse+\\'.png\\')\\n                grid.visualize_current_field(snr_map=snr_map,\\n                                            save_dir=subdir+\"GridVisual2\"+name_parse+\\'.png\\',\\n                                            min_lat=0.1, \\n                                            max_lat=3.0)\\n                \\n                \\nprint(\"\\tslice directory count:\", slice_count) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## filter out no-response grid squares by SNR cutoff (or manual inspection?)\n",
    "###   Read in the SNR/latency files/roi center files\n",
    "slice_count = 0\n",
    "for slic in image_data:\n",
    "    for loc in image_data[slic]:\n",
    "        for rec in image_data[slic][loc]:\n",
    "            for subdir in image_data[slic][loc][rec]:\n",
    "                slice_count += 1\n",
    "                def pad_z2(x):\n",
    "                    x = str(x)\n",
    "                    while len(x) < 2:\n",
    "                        x = '0' + x\n",
    "                    return x\n",
    "                \n",
    "                rec_id = pad_z2(slic) + \"_\" + pad_z2(loc) + \"_\" + pad_z2(rec)\n",
    "                \n",
    "                filename_end = \"_rois_\" + rec_id + \".dat\"\n",
    "                snr_filename = subdir + \"/\" + \"SNR_\" + filename_end\n",
    "                latency_filename = subdir + \"/\" + \"latency_\" + filename_end \n",
    "                roi_center_filename = subdir + \"/\" + rois_centers_filenames\n",
    "\n",
    "\n",
    "                snr_df = pd.read_csv(snr_filename, sep='\\t', header=None,\n",
    "                                     names=['Index',  'SNR'])\n",
    "                latency_df = pd.read_csv(latency_filename, sep='\\t', header=None,\n",
    "                                     names=['ROI Index',  'Latency'])\n",
    "                roi_center_df = pd.read_csv(roi_center_filename, sep='\\t', header=None,\n",
    "                                     names=['Center x',  'Center y'])\n",
    "                \n",
    "                combined_df = roi_center_df.join(latency_df)\n",
    "                combined_df = combined_df.join(snr_df[['SNR']])\n",
    "                print(subdir, rec_id)\n",
    "                \n",
    "                ############## Analysis: ############################\n",
    "                ##### 1) directed graph analysis of latency #########\n",
    "                ##### 2) 3-D plot of latency ########################\n",
    "                ##### 3) 3-D plot of SNR ############################\n",
    "                #####################################################\n",
    "                \n",
    "                # 1) directed graph analysis of latency\n",
    "                nd_list = [Node([row[['Center x']][0], row[['Center y']][0]],\n",
    "                                 row[['Latency']][0],\n",
    "                                 row[['SNR']][0]) for _, row in combined_df.iterrows()]\n",
    "                grid = Grid(nd_list, n_sq, latency_tolerance=latency_tolerance)\n",
    "                \n",
    "                ## a) determine latency ordering on directed graph\n",
    "                grid.populate_latency_matrix()\n",
    "                grid.calculate_current_field()  # current flow vectors of all nodes\n",
    "                \n",
    "                ## b) visualize\n",
    "                snr_map = None\n",
    "                try:\n",
    "                    snr_map = image_data[slic][loc][rec][subdir]['snr_map']\n",
    "                except Exception as e:\n",
    "                    snr_map = np.zeros((80, 80))  # default\n",
    "                grid.visualize_spatial_flow(snr_map=snr_map,\n",
    "                                            save_dir=subdir+\"GridVisual1\"+name_parse+'.png')\n",
    "                grid.visualize_current_field(snr_map=snr_map,\n",
    "                                            save_dir=subdir+\"GridVisual2\"+name_parse+'.png',\n",
    "                                            min_lat=0.1, \n",
    "                                            max_lat=3.0)\n",
    "                \n",
    "                \n",
    "print(\"\\tslice directory count:\", slice_count) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2fecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
